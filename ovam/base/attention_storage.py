"""Class in charge of storing the hidden states of a block.

The class OnlineAttentionStorage allows a simple version that 
stores all the hidden states in memory. The AttentionStorage
class is a generic class that can be used to implement more
complex storage classes.

"""

from typing import TYPE_CHECKING, Any, Iterable, Optional, List, Union

# if TYPE_CHECKING:
import torch
from torch import nn
from torch.nn.modules.container import ParameterList
from torch.nn import Parameter

__all__ = ["AttentionStorage", "OnlineAttentionStorage", "ParameterListConfigurable"]


class ParameterListConfigurable(ParameterList):
    def __init__(
        self,
        values: Optional[Iterable[Any]] = None,
        disable_grad: bool = False,
        off_load_to_cpu: bool = False,
    ) -> None:
        self.disable_grad = disable_grad
        self.off_load_to_cpu = off_load_to_cpu
        super().__init__(values)

    def __setitem__(self, idx: int, param: Any) -> None:
        # Note that all other function that add an entry to the list part of
        # the ParameterList end up here. So this is the only place where we need
        # to wrap things into Parameter if needed.
        # Objects added via setattr() are not in the list part and thus won't
        # call into this function.
        idx = self._get_abs_string_index(idx)
        if isinstance(param, torch.Tensor) and not isinstance(param, Parameter):
            if (
                self.off_load_to_cpu
            ):  # NOTE: if you move .to after Parameter, doesn't work
                param = Parameter(
                    param.to("cpu", non_blocking=True),
                    requires_grad=not self.disable_grad,
                )
            else:
                param = Parameter(param, requires_grad=not self.disable_grad)
        return setattr(self, str(idx), param)


class AttentionStorage(nn.Module):
    """Generic class for storing hidden states of upsample/downsample block.

    Attributes
    ----------
    name: str
        The name of the block in the UNet.
    """

    def __init__(self, name: Optional[str] = None) -> None:
        super().__init__()
        self.name = name

    def store(self, hidden_states: "torch.Tensor") -> None:
        """Stores the hidden states.

        Arguments
        ---------
        hidden_states: List[torch.Tensor]
            The hidden states of a block generated by an image. The
            hidden states are stored in the order they are passed.
        """
        raise NotImplementedError

    def __len__(self) -> int:
        """Returns the number of images stored"""
        raise NotImplementedError

    def __getitem__(self, idx: int) -> "torch.Tensor":
        """Returns the hidden state at the given index."""
        raise NotImplementedError

    def __iter__(self) -> Iterable["torch.Tensor"]:
        """Returns an iterator over the stored hidden states."""
        for i in range(len(self)):
            yield self[i]

    def clear(self) -> None:
        """Clears the stored hidden states."""
        raise NotImplementedError


class OnlineAttentionStorage(AttentionStorage):
    """Class to store the hidden states in memory.

        Attributes
    ----------
    block_name: str
        The name of the block in the UNet.
    """

    def __init__(self, name: Optional[str] = None, use_default: bool = False):
        super().__init__(name)
        if use_default:
            self.hidden_states = ParameterList()
        else:
            self.hidden_states = ParameterListConfigurable(
                disable_grad=True, off_load_to_cpu=True
            )

    def store(self, hidden_states: "torch.Tensor") -> None:
        """Stores the hidden states.

        Arguments
        ---------
        hidden_states: List[torch.Tensor]
            The hidden states of a block generated by an image. The
            hidden states are stored in the order they are passed.
        """
        self.hidden_states.append(hidden_states)

    def __len__(self) -> int:
        return len(self.hidden_states)

    def __getitem__(self, idx: int) -> "torch.Tensor":
        return self.hidden_states[idx]

    def clear(self) -> None:
        """Clears the stored hidden states."""
        self.hidden_states.clear()
